* System architecture

#+begin_ditaa system-architecture.png

                                     +-------------+
             +---------------------> |  {s}        |
             |                       |   Prolog    |
             |                       +-------------+
             v                              ^
    +-----------------+                     |
    |   High Level    |                     v
    |     Actions     |           +-------------------+
    |     (Plans)     | --------> |   Belief state    |<-----------+
    |                 |           |     (Rete)        |            |
    +-----------------+           +-------------------+            |
             |                                                     |
             |            Designators                              |
         +---+------------------+-----------------------+          |
         |                      |                       |          |
         v                      v                       v          |
  +--------------+       +--------------+       +---------------+  |
  |  Perception  |       |  Navigation  |       |  Manipulation |  |  Process Modules
  |              |       |              |       |               |  |
  +--------------+       +--------------+       +---------------+  |
         ^                      ^                       ^          |
         |                      |                       |          |
         +----------------------+-----------------------+----------+
                         Rete Tokens

#+end_ditaa

** High Level Actions
   The high-level actions include activity such as:
   - Pick up an object
   - Put down an object
   - Pick-and-place object

   All actions are implemented as plans, i.e. control programs that
   contain annotations about their purpose. For instance,
   [[file:~/work/ros/tumros-internal/highlevel/kipla/src/goals/achieve-object-manipulation.lisp][achieve-object-manipulation.lisp]] defines several goals.

   A goal is defined with =def-goal=, which takes a pattern and a code
   body. Patterns are statements that indicate the purpose of a plan
   and are grounded in the underlying ontology. E.g. informally
   speaking, =(achieve (object-in-hand ?obj))= states that the
   corresponding body signals successful iff the system beliefs that
   the object is in the robot's gripper after execution. Please note
   that occasion statements such as =(object-in-hand ?obj)= are
   asserted in the Rete alpha network of the belief state. Currently,
   this must be done manually, but an implicit mechanism is planned.

*** TODO Add summary and documentation of current goals

** Process Modules
   Process modules are the interface to low level components. The
   current system knows
   - Perception
   - Navigation
   - Manipulation
     
   Process modules always get a designator as input and transform this
   designator to parameters that are understood by the ros modules
   that perform a specific action. For instance, navigation gets a
   location designator. The following code shows an example of a
   designator that describes a location where an object can be seen.
   
#+BEGIN_SRC
   (location (to see) (obj ?obj))
#+END_SRC

   By using the semantic map (TODO), a location close to the object is
   calculated and the ros action to reach it is executed.

   A more complex example is grasping. The high-level plan to grasp an
   object works like this:
   1) Drive to the location =(location (to see) (obj ?obj))=
   2) Look for the object
   3) Drive to the location =(location (to reach) (obj ?obj))=, which
      normally is the same location as the previous one (to see).
   4) Create a reaching designator, e.g. =(action (type trajectory)
      (to grasp) (obj ?obj) (side ?side))=
   5) Try to reach. If the reach fails because the object is not
      reachable, invalidate the current reaching location and
      calculate a new one (rotated around z) and retry.

   Process modules always get a designators as input and may return a
   designator.

   Process will allow for plan projection. Since their interface is
   clearly defined by designators, it is possible to replace them to
   work on different robots, in simulation or more symbolic
   mechanisms. For plan debugging, it will be necessary to define the
   semantics of process modules by declare events that are generated
   and maybe some temporal constraints on the events.

* Perception

** Perception Designator Concepts
   Designators provide an interface between the symbolic world of a
   plan and low-level perception routines. Although designators are
   also used for manipulation parameterizion locations, we describe
   only the perception subsystem in this section.

   First of all, designators are a set of property tuples. The
   following properties are currently supported:
   - (type <type>) with type being one of:
     - mug
     - icetea
     - cluster
     - jug
     - placemat
     - coke
   - (color <color>) with color being one of:
     - black
     - red
   - (at <location desig>): Gets a location designator that resolves
     to a valid pose-id that indicates where to search for the object.

   From these properties, an object that can be sent to COP needs to be
   generated. In the future, there might be additional (maybe passive)
   perception mechanisms that also need to resolve the set of
   properties. To account for this requirement, object designators are
   resolved by a resolver. Resolvers are defined by a name (the
   property) as well as a namespace ([[file:~/work/ros/tumros-internal/highlevel/kipla/src/designators/object-designators.lisp::defmacro%20register%20object%20desig%20resolver%20name%20namespace%20prev%20param%20desig%20param%20body%20body][register-object-desig-resolver]])
   Resolvers work somehow like reduce. The declaration gets a name and
   the namespace plus two parameters. `prev-param' is the result of the
   previous resolver and `desig-param' is the designator to be
   resolved.


** Belief State Management and Anchoring of Percepts (planned!)

  The following figure gives an overview how perception is intended to
  work.
#+begin_ditaa perception-overview.png

                                  +----------+
                                  |  {s}     |
                                  |  Prolog  |
                                  |          |
                                  +----------+
                                        |
                                        |
                                        v
+---------------+             +--------------------+     +-------------------+
|               |             |                    |     |                   |
|  Designator   |------------>|  Rete Production   |---->| Output Designator |
|               |             |                    |     |                   |
+---------------+             +--------------------+     +-------------------+
       |                                ^
       v                                |
+---------------+             +--------------------+
|               |             |                    |
|   Resolver    |             | Rete Alpha Tokens  |
|               |             |                    |
+---------------+             +--------------------+
       |                                ^
       v                                |
+----------------------+      +--------------------+
|                      |      |                    |
| Perception Component |----->+  Perceived object  |
|                      |      |                    |
+----------------------+      +--------------------+

#+end_ditaa

  The input to the perception subsystem is a designator. It is
  resolved by some resolver. Currently, it is undecided how many and
  which namespaces will be defined and how the decision is made which
  one to use. The generated data object is passed over to a perception
  algorithm which returns a PERCEIVED-OBJECT instance, as defined in
  [[file:~/work/ros/tumros-internal/highlevel/kipla/src/perception/object-belief.lisp][object-belief.lisp]]. This instance contains a set of attributes that
  could be perceived, e.g. color, some identifier for the 3d model or
  similar things. These attributes, in conjunction with some of the
  input attributes, are then split up into tokens of the form:
  (<attribute name> <perceived object instance> <attribute value>)

  Besides resolving the designator, a production node for a Rete beta
  network has been created, too. It is basically a conjunction of all
  its attributes in the token form as shown above. By propagating the
  perceived object tokens through the Rete network, all productions
  that were generated from designators get triggered. This should lead
  to an implicit designator resolution. Another interesting feature
  should be that besides designator productions, prolog production
  nodes can be added that make additional assertions, such as spacial
  relationships (on, left-of, right-of, ...)

  When previous productions are triggered, the system can decide if
  the two objects are the same, e.g. by matching the
  pose. Compatibility of attributes is already assured by using the
  Rete production. That means, anchoring could be quite easy
  (hopefully).
