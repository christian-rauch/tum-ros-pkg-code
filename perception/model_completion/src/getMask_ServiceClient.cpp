#include <ros/ros.h>
#include <ros/node_handle.h>
#include <cstdlib>
#include <robot_mask/GetMask.h>
#include <opencv/cv.h>
#include <opencv/highgui.h>
#include <string.h>
#include "cv_bridge/CvBridge.h"
#include <opencv2/highgui/highgui.hpp>
#include <boost/thread.hpp>
#include <sensor_msgs/Image.h>
#include <message_filters/subscriber.h>
#include <sensor_msgs/image_encodings.h>
#include <siftfast/siftfast.h>

using namespace message_filters;
using namespace cv::flann;
using namespace cv;
const int COLORS = 13;

class LatestMatchingTFMessage
{
private:
    ros::Subscriber tf_sub_;
    ros::Subscriber image_sub_;
    std::string source_frame_, camera_frame_;
    int fovy_, width_, height_, count_ ;
    ros::NodeHandle nh_;
    bool valid_, save_images_;
    double radius_;
public:
    ros::ServiceClient client ;
    robot_mask::GetMask srv;
    tf::tfMessageConstPtr tf_state , last_matching_tf;
    cv::Mat mask, original_image , final_image;
    std::string tf_topic_, image_topic_;
    sensor_msgs::CvBridge bridge_;

    std::vector<unsigned int> cluster_sizes;
    int min_cluster_size;
    IplImage *camera_image, *template_image, *image_ ,*image_roi;
    CvScalar color_table[COLORS];

    Mat query, indices ,dists;
    Index * index;

    LatestMatchingTFMessage(ros::NodeHandle &nh, const std::string &source_frame)
    : source_frame_(source_frame),
      nh_ (nh),
      valid_(false)
    {
        //subscribe the tf_topic and image_topic
        nh_.param("tf_topic", tf_topic_, std::string("/tf"));
        nh_.param("image_topic", image_topic_, std::string("/narrow_stereo/left/image_rect"));
        tf_sub_ = nh_.subscribe(tf_topic_, 1, &LatestMatchingTFMessage::TFcallback, this);
        image_sub_ = nh_.subscribe(image_topic_, 1, &LatestMatchingTFMessage::Imagecallback, this);

        //parameters
        nh_.param("radius",radius_,100.0);
        nh_.param("fovy", fovy_, 25);
        nh_.param("width", width_, 640);
        nh_.param("height", height_, 480);
        nh_.param("camera_frame", camera_frame_, std::string("narrow_stereo_optical_frame"));
        nh_.param("save_images", save_images_, false);
        srv.request.width = width_;
        srv.request.height = height_;
        srv.request.fovy = fovy_;
        srv.request.camera_frame = camera_frame_;
        count_ = 0;

        //create a new window named Mask for see the cv::Mat img
        cv::namedWindow("Final Image", CV_WINDOW_AUTOSIZE);
        //cv::namedWindow("Original Image", CV_WINDOW_AUTOSIZE);
        cv::namedWindow("Keypoints Image",CV_WINDOW_AUTOSIZE);
        //instantiate an autogenerated service class, and assign values into its request member.
        client = nh.serviceClient<robot_mask::GetMask>("/robot_mask/get_mask");
        //create the cv::Mat to copy the values from the mask[] into it
        //Mat::Mat(int rows, int cols, int type)
        mask.create(srv.request.height ,srv.request.width,CV_8UC1);
        final_image.create(srv.request.height ,srv.request.width,CV_8UC1);
        query.create(1000, 2, CV_32FC1);
        indices.create(1000, 1000, CV_32SC1);
        dists.create(1000, 1000, CV_32FC1);

        //color table - used for the visualization only
        color_table[0] = cvScalar(255, 0, 0);
        color_table[1] = cvScalar(0, 255, 0);
        color_table[2] = cvScalar(0, 0, 255);
        color_table[3] = cvScalar(255, 255, 0);
        color_table[4] = cvScalar(255, 0, 255);
        color_table[5] = cvScalar(0, 255, 255);
        color_table[6] = cvScalar(255, 255, 255);
        color_table[7] = cvScalar(125, 255, 255);
        color_table[8] = cvScalar(255, 125, 255);
        color_table[9] = cvScalar(255, 255, 125);
        color_table[10] = cvScalar(125, 125, 255);
        color_table[11] = cvScalar(255, 125, 125);
        color_table[12] = cvScalar(125, 255, 125);
    }
    /////////////////////////////////////////////////
    bool getTF(tf::tfMessageConstPtr& ret)
    {
        ros::Rate r(100);
        while(!valid_)
        {
            if (nh_.ok())
                r.sleep();
            else
                return false;
        }
        ret = last_matching_tf;
        return true;
    }
    /////////////////////////////////////////////////////////
    void TFcallback(const tf::tfMessageConstPtr &msg )
    {
        if(!valid_)
        {
            if(msg->transforms[0].header.frame_id == source_frame_)
            {
                last_matching_tf = msg;
                valid_ = true;
            }
        }
    }
    /////////////////////////////////////////////////////////
    void Imagecallback(const sensor_msgs::ImageConstPtr& image )
    {
        ROS_INFO("[LatestMatchingTFMessage:] Image received in frame: %s with height %d and width %d",
                image->header.frame_id.c_str(), image->height, image->width);
        if(valid_)
        {
            srv.request.tf_state = *last_matching_tf;
            ROS_INFO("[LatestMatchingTFMessage:] waiting for service server...");
            if(!client.waitForExistence (ros::Duration (1)))
            {
                ROS_ERROR("[LatestMatchingTFMessage:] Could not find service.");
            }
            //convert the ros::image in cv::image
            try
            {
                original_image = bridge_.imgMsgToCv(image);
                ROS_INFO("[LatestMatchingTFMessage:] Image converted");
            }
            catch (sensor_msgs::CvBridgeException error)
            {
                ROS_ERROR("error");
            }
            ROS_INFO("[LatestMatchingTFMessage:] The server was found - calling now");
            // calls the service
            if (client.call(srv))
            {
                //fill the mask image with the data from srv.response.mask
                //copy the first 640 elements from mask array into first row of cv::Mat and so on..
                for (unsigned int i=0; i < srv.response.mask.size(); i++)
                {
                    if (srv.response.mask[i] == 1)
                        mask.at<uint8_t>(i/mask.cols, i%mask.cols) = 0;
                    else
                        mask.at<uint8_t>(i/mask.cols, i%mask.cols) = 255;
                }
                //make the padding around the gripper mask
                for (int i=0; i < mask.rows; i++)
                {
                    for ( int j = 0; j < mask.cols; j++)
                    {
                        if (mask.at<uint8_t>(i,j-1) == mask.at<uint8_t>(i,j))
                            mask.at<uint8_t>(i,j-1) = mask.at<uint8_t>(i,j);
                        else
                        {
                            mask.at<uint8_t>(i,j-1) = 0;
                            mask.at<uint8_t>(i,j-2) = 0;
                            mask.at<uint8_t>(i,j-3) = 0;
                            mask.at<uint8_t>(i,j-4) = 0;
                            mask.at<uint8_t>(i,j-5) = 0;
                            mask.at<uint8_t>(i,j-6) = 0;
                            mask.at<uint8_t>(i,j-7) = 0;
                            mask.at<uint8_t>(i,j-8) = 0;
                            mask.at<uint8_t>(i,j-9) = 0;
                            mask.at<uint8_t>(i,j-10) = 0;
                            mask.at<uint8_t>(i,j-11) = 0;
                            mask.at<uint8_t>(i,j-12) = 0;
                            mask.at<uint8_t>(i,j-13) = 0;
                            mask.at<uint8_t>(i,j-14) = 0;
                            mask.at<uint8_t>(i,j-15) = 0;
                        }
                    }
                }
            }
            else
            {
                ROS_ERROR("[LatestMatchingTFMessage:] Failed to call service robot_mask");
            }
            ROS_INFO("after service call");
            //getting the image without the robot hand
            final_image.zeros(srv.request.height, srv.request.width, CV_8UC1);
            //--Calculates per-element bit-wise conjunction of two arrays in a final one
            bitwise_and(original_image, mask, final_image);
            // original_image.copyTo(mask);
        }
        valid_=false;
        Keypoint template_keypoints = extract_keypoints(final_image);
        Keypoint template_keypoints1 = template_keypoints;
        Keypoint template_keypoints2 = template_keypoints;
        extract_roi(final_image, template_keypoints);
        //visualize(final_image , template_keypoints1);


        //for calling the radiusSearch function
        int query_rows = 0;
        for (int k=0; template_keypoints2 != NULL; ++k, template_keypoints2 = template_keypoints2->next)
        {
            // at<T>(rowIndex, colIndex)
            query.at<float>(k, 0) = template_keypoints2->col;
            query.at<float>(k, 1) = template_keypoints2->row;
            query_rows = k;
        }
        //resize query and indices matrix to actual sizes of template_keypoints
        Mat query_point(1,2,CV_32FC1);
        query_point.at<float>(0, 0) = 338;
        query_point.at<float>(0, 1) = 248;
        query.resize(query_rows+1);
        indices.resize(query_rows+1, query_rows+1);
        dists.resize(query_rows+1, query_rows+1);
        //populate index tree
        // When passing an object of LinearIndexParams type, the index will perform a linear, brute-force search.
        index = new Index (query, LinearIndexParams() );
        //search for neighbors
        radiusSearch(query_point,indices,dists);
        //visualize(query,indices,final_image);
        //cv::Mat temp(image_);
        delete index;
        //print indices of neighbors
        //TODO: find out how to print indices from the below pointer


        for (int i = 0; i < indices.rows; i++)
        {
            std::cerr << "indices:";
            for (int j = 0; j < indices.cols; j++)
            {
                int *pt = indices.ptr<int>(j);
                if (pt[0] > 0)
                    std::cerr << pt[0] << " ";
                //indices.pt
            }
            std::cerr << std::endl;
        }

        //TODO: chose the keypoint from the query matrix that is the closest to e.g. milk's center
        //which query point has the closest distance to
        //my_query_point = query.at<float>(336.0 , 268.0);

        //TODO:  print out and visualize neighbors from the above center keypoint
        //std::cerr << "indices: " << pt1[my_query_point] << " ";
        //std::cerr << std::endl;

        //TODO: play with radius parameter from radiusSearch function and observe how the number of neighbors vary
        // index->radiusSearch( q, in, dists_mat, 20.0f, SearchParams() );

        //TODO: call extract_roi after you have filtered out outliers
        //extract_roi(final_image, template_keypoints2);
        //visualize(final_image , template_keypoints2);

        //display window on the screen
        //cv::imshow("Original Image", original_image);
        //cv::imshow("Final Image", final_image);
        //cv::imshow("Keypoints Image", temp);
        //cv::waitKey(10);

        //save the image to Mask.png
        /*if (save_images_)
        {
            count_++;
            std::stringstream ss;
            ss << count_;
            cv::imwrite(ss.str() + ".png", temp);
            cv::imwrite(ss.str() + "a.png", original_image);
        }
         */
    }
    //remove SIFT features through clustering //match locations of SIFT features
    // the radiusSearch returns no more nearest neighbors then indices (or dists) cols.
    void radiusSearch(Mat& query, Mat& indices, Mat& dists)
    {
        // radiusSearch can only search one feature at a time for range search
        for( int i = 0; i < query.rows; i++ )
        {
            //1st way
            Mat q( 1, query.cols, CV_32FC1, query.ptr<float>(i) );
            Mat  in( 1, indices.cols, CV_32SC1, indices.ptr<int>(i) );
            Mat di(1,dists.cols,CV_32FC1, dists.ptr<float>(i));
            index->radiusSearch( q, in, di, radius_, SearchParams() );

            //2nd way
            // float* fltPtr = query.ptr<float>(i);
            // vector<float> q( fltPtr, fltPtr + query.cols );
            // vector<int> in( indices.cols, 0 );
            // vector<float> dists( dists_mat.cols, 0 );
            // index->radiusSearch( q, in, dists, 100.0f, SearchParams() );
            // vector<int>::const_iterator it = in.begin();
            // std::cerr << "size: " << in.size() << std::endl;
            // // for(int j = 0; it != in.end(); ++it, j++ )
            // //   std::cerr << "indices: " << *it;
            // std::cerr << std::endl;
        }
    }

    Keypoint extract_keypoints(IplImage image, bool frames_only = false)
    {
        Image sift_image = CreateImage(image.height, image.width);
        for (int i = 0; i < image.height; ++i)
        {
            uint8_t* pSrc = (uint8_t*) image.imageData + image.widthStep * i;
            // 2D array of image pixels.
            // int stride -- how many floats until the next row
            // (used to add padding to make rows aligned to 16 bytes)
            float* pDst = sift_image->pixels + i * sift_image->stride;
            for (int j = 0; j < image.width; ++j)
                pDst[j] = (float) pSrc[j] * (1.0f / 255.0f);
        }
        Keypoint keypoints;
        if (frames_only)
            keypoints = GetKeypointFrames(sift_image);
        else
            keypoints = GetKeypoints(sift_image);
        DestroyAllImages();
        return keypoints;
    }

    void extract_roi(IplImage image1, Keypoint &camera_keypoints)
    {
        IplImage *image = cvCreateImage( cvSize(image1.width, image1.height), image1.depth, image1.nChannels );
        *image = image1;
        //create a sequence storage for projected points
        CvMemStorage* stor = cvCreateMemStorage (0);
        CvSeq* seq = cvCreateSeq (CV_SEQ_ELTYPE_POINT, sizeof (CvSeq), sizeof (CvPoint), stor);
        for (int ii=0; camera_keypoints != NULL; ++ii, camera_keypoints = camera_keypoints->next)
        {
            cv::Point2d uv;
            CvPoint pt;
            pt.x = camera_keypoints->col;
            pt.y = camera_keypoints->row;
            cvSeqPush( seq, &pt );
        }
        //draw rectangle around the points
        CvRect rect = cvBoundingRect(seq);
        ROS_DEBUG_STREAM("rect: " << rect.x << " " << rect.y << " " << rect.width << " " << rect.height);
        //get subimage, aka region of interest
        cvSetImageROI(image,rect);
        //sub-image
        image_roi = cvCreateImage( cvSize(rect.width, rect.height), image->depth, image->nChannels );
        cvCopy(image, image_roi);
        cvResetImageROI(image); // release image ROI
        return;
    }

    void visualize(IplImage camera_image_in1, Keypoint &camera_keypoints)
    {
        IplImage *camera_image_in = cvCreateImage( cvSize(camera_image_in1.width, camera_image_in1.height),
                camera_image_in1.depth, camera_image_in1.nChannels );
        *camera_image_in = camera_image_in1;
        image_ = cvCreateImage(cvSize(camera_image_in->width, camera_image_in->height),
                camera_image_in->depth, 3);
        cvCvtColor(camera_image_in, image_, CV_GRAY2RGB);
        // display camera image keypoints
        for (int ii=0; camera_keypoints != NULL; ++ii, camera_keypoints = camera_keypoints->next)
        {
            cvCircle(image_, cvPoint((int) (camera_keypoints->col),
                    (int) (camera_keypoints->row)), 3,
                    color_table[1]);
        }
    }

    void visualize(Mat& query, Mat& indices , IplImage camera_image_in1)
    {
        IplImage *camera_image_in = cvCreateImage( cvSize(camera_image_in1.width, camera_image_in1.height),
                camera_image_in1.depth, camera_image_in1.nChannels );
        *camera_image_in = camera_image_in1;
        image_ = cvCreateImage(cvSize(camera_image_in->width, camera_image_in->height),
                camera_image_in->depth, 3);
        cvCvtColor(camera_image_in, image_, CV_GRAY2RGB);
        // display camera image keypoints
        for (int ii=0; ii< indices.cols; ++ii)
        {
            cvCircle(image_, cvPoint((int) (query.at<uint8_t>(ii, 0)),
                    (int) (query.at<uint8_t>(ii, 1))), 3,
                    color_table[1]);
        }
    }
};
/////////////////////////////////////////////////////
int main(int argc, char **argv)
{
    //get_mask_client - the node name for client , get_mask - node for the server
    ros::init(argc, argv, "get_mask_client");
    ros::NodeHandle n("~");
    LatestMatchingTFMessage tf(n, "/base_footprint");
    //enters a loop, calling message callbacks as fast as possible
    ros::spin();
}
